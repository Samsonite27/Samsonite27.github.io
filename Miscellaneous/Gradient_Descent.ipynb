{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIcAx2X8B5V3X3Jw7wdztX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samsonite27/Samsonite27.github.io/blob/main/Miscellaneous/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider some function, $\\mathcal{M}: \\mathbb{R^n} → \\mathbb{R}$, let $\\mathcal{M}_n \\in \\mathcal{P}_n = \\{p \\in \\mathbb{F}[x] \\text{ | deg(p) = n} \\}$\n",
        "\n",
        "Then there exists some $(a_0, a_1, \\dots, a_n), \\text{ where } a_i \\in \\mathbb{R}$.\n",
        "\n",
        "That define $\\mathcal{M}_n = a_0 + a_1x + a_2x^2 + \\dots a_nx^n$\n",
        "\n",
        "For each model, let's define some mean error squared function.\n",
        "\n",
        "Given some sample data, define $\\text{MSE: } \\mathbb{R}^k \\times \\mathcal{P}_n → \\mathbb{R}$\n",
        "\n",
        "Where $\\text{MSE}((x_i, y_i)^n_{i = 1}, \\mathcal{M}_n) =  \\frac{1}{n} \\sum_{i=1}^n (y_i - \\mathcal{M}_n(x_i))^2$\n",
        "\n",
        "For a specific set of data, $\\text{MSE}(a_0, a_1, a_2, \\dots, a_n )$\n",
        "\n",
        "We can caluclate $∇\\text{MSE}$,  $\\text{MSE}_{a_j} = -\\frac{2}{n} \\sum_{i=1}^n x_i^j \\left(y_i - \\sum_{k=1}^m a_k x_i^k \\right)$\n",
        "\n",
        "Then we can write write a gradient descent function to find locally minimal values of $a_0, ..., a_n$"
      ],
      "metadata": {
        "id": "l4Mbg90-6exA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Misr4aIi6ND9",
        "outputId": "4cdda05f-7d48-4f65-f2b8-64f072f69401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([-9.499919430004864, 10.749909011726272, -2.2499783259241006],\n",
              " 1.1250000000893405)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def polynomial(coefficients, input):\n",
        "  sum = 0\n",
        "\n",
        "  for i in range(len(coefficients)):\n",
        "    sum += coefficients[i] * (input ** i)\n",
        "\n",
        "  return sum\n",
        "\n",
        "def MSE(points, coefficients):\n",
        "\n",
        "  n = len(points)\n",
        "  sum = 0\n",
        "\n",
        "  for i in range(len(points)):\n",
        "    sum += (points[i][1] - polynomial(coefficients, points[i][0])) ** 2\n",
        "\n",
        "  return 1/n * sum\n",
        "\n",
        "def negative_gradient_polynomial(points, coefficients):\n",
        "\n",
        "  grad = []\n",
        "\n",
        "  for j in range(len(coefficients)):\n",
        "    sum = 0\n",
        "    for i in range(len(points)):\n",
        "      sum += (points[i][0] ** j) * (points[i][1] - polynomial(coefficients, points[i][0]))\n",
        "    grad.append(2 *sum/len(points))\n",
        "\n",
        "  return grad\n",
        "\n",
        "negative_gradient_polynomial([[1, 2], [2, 3]], [1, 2, 3])\n",
        "\n",
        "def gradient_descent(points, initial_coefficients, step_size, trials):\n",
        "\n",
        "  coefficients = initial_coefficients\n",
        "\n",
        "  for i in range(trials):\n",
        "    gradient_vector = negative_gradient_polynomial(points, coefficients)\n",
        "    coefficients = [coefficients[i] + gradient_vector[i] * step_size for i in range(len(coefficients))]\n",
        "\n",
        "  return (coefficients, MSE(points, coefficients))\n",
        "\n",
        "gradient_descent([[1, -1], [2, 3], [3, 1], [3, 4]], [2, 1, 1], 0.01, 100000)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKYP54G46acP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}